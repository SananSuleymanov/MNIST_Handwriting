{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sanan_Suleymanov_MNIST_hw2.ipynb",
      "provenance": [],
      "mount_file_id": "101JIUgqFvd3VUjHpltNkNy0FhdlvU-cU",
      "authorship_tag": "ABX9TyO8a87VKkWQvvSzTBqx25Nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SananSuleymanov/MNIST_Handwriting/blob/main/Sanan_Suleymanov_MNIST_hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsYzzdqtJ2ST",
        "outputId": "c6a8b22f-db20-4305-ad74-ecf3a23ac51c"
      },
      "source": [
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import decode_predictions\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras.models import Model\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from google.colab import files\n",
        "\n",
        "\n",
        "# Export saved model\n",
        "export_dir = 'mymodel'\n",
        "\n",
        "\n",
        "# Load and prepare MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Normalize dataset\n",
        "(x_train1, y_train) , (x_test1, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train1 / 255.0\n",
        "x_test = x_test1 / 255.0\n",
        "\n",
        "# Build sequential model by stacking layers, choose optimizer and loss function\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(70, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(60, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.summary()\n",
        "\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions_prob = tf.nn.softmax(predictions).numpy()\n",
        "print ('Probabilities for each class: ' + str(predictions_prob))\n",
        "\n",
        "# Take a vector of logits and True index and return scalar loss for each example\n",
        "# This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_initial = loss_fn(y_train[:1], predictions).numpy()\n",
        "print('Untrained model inital loss: ' + str(loss_initial))\n",
        "\n",
        "# Train model\n",
        "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "# Adjust model parameters to minimize the loss and train it\n",
        "model.fit(x_train, y_train, epochs=20)\n",
        "\n",
        "# Evaluate model performance\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=2)\n",
        "#model.save(\"mnist_keras.h5\")\n",
        "#files.download(\"mnist_keras.h5\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 70)                54950     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               7100      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 60)                6060      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 60)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,720\n",
            "Trainable params: 68,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Probabilities for each class: [[0.09283282 0.07663745 0.10198117 0.11097066 0.10612822 0.09392064\n",
            "  0.10808406 0.10209717 0.11955711 0.08779071]]\n",
            "Untrained model inital loss: 2.3653052\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2994 - accuracy: 0.9107\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1320 - accuracy: 0.9617\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0964 - accuracy: 0.9707\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0779 - accuracy: 0.9761\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0654 - accuracy: 0.9798\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9829\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0494 - accuracy: 0.9845\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0414 - accuracy: 0.9868\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0376 - accuracy: 0.9880\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0368 - accuracy: 0.9885\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0315 - accuracy: 0.9901\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0296 - accuracy: 0.9903\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0269 - accuracy: 0.9915\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0255 - accuracy: 0.9923\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0248 - accuracy: 0.9923\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.9935\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0223 - accuracy: 0.9932\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0184 - accuracy: 0.9942\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0218 - accuracy: 0.9934\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0190 - accuracy: 0.9937\n",
            "313/313 - 0s - loss: 0.1312 - accuracy: 0.9769 - 486ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13120229542255402, 0.9768999814987183]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdv8mLB1rnG",
        "outputId": "1b3ca1b6-2b54-4ed8-eeda-6072cd8d9d58"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('/content/mnist_keras.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpoqbqjoe4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpoqbqjoe4/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "277528"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "v35lyBVQRmK2",
        "outputId": "7c0e77e7-cedd-4186-d771-21c3f63b4f42"
      },
      "source": [
        "loaded_images = list()\n",
        "for filename in listdir('/content/drive/MyDrive/Colab Notebooks/mnist own'):\n",
        "  im = plt.imread('/content/drive/MyDrive/Colab Notebooks/mnist own/'+filename)\n",
        "  loaded_images.append(im)\n",
        "\n",
        "\n",
        "x_own = np.array(loaded_images)\n",
        "\n",
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])\n",
        "time1_k = time.time()\n",
        "predictions = probability_model.predict([x_own])\n",
        "time2_k= time.time()\n",
        "print((time2_k-time1_k)/10)\n",
        "print(predictions.shape)\n",
        "print(np.argmax(predictions[0]))\n",
        "plt.imshow(x_own[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39dc08f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.009521698951721192\n",
            "(10, 10)\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa398a6eb50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWA16zinXTsC",
        "outputId": "336cf9ff-1af8-4133-845b-3fe84654d0a3"
      },
      "source": [
        "def rgb2gray():\n",
        "  for filename in listdir('/content/sample_data/mnist_org'):\n",
        "      im = cv2.imread('/content/sample_data/mnist_org/'+filename, cv2.IMREAD_GRAYSCALE)\n",
        "      im_gray =cv2.imwrite('/content/sample_data/mnist_new/'+filename, im)\n",
        "  \n",
        "  return im_gray\n",
        "\n",
        "new_rgb = rgb2gray()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "YtgI-SSvqiU1",
        "outputId": "ed7cd621-e6fa-449c-d137-442bd8d7c834"
      },
      "source": [
        "#convertion of image from single layer to RGB\n",
        "def gray2rgb(image):\n",
        "  new_im = list()\n",
        "  for i in range (len(image)):\n",
        "    rgb = cv2.cvtColor(image[i], cv2.COLOR_GRAY2RGB)\n",
        "    res_im = cv2.resize(rgb, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    new_im.append(res_im)\n",
        "\n",
        "  \n",
        "  rgb_im = np.array(new_im)\n",
        "  \n",
        "  return rgb_im\n",
        "\n",
        "new_rgb = gray2rgb(x_own)\n",
        "\n",
        "print(new_rgb[0].shape)\n",
        "plt.imshow(new_rgb[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa39dc1a590>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkcpBOGg_DLy",
        "outputId": "90935722-df99-4b41-a809-71d1f605b13e"
      },
      "source": [
        "\n",
        "data = preprocess_input(new_rgb)\n",
        "base_model = MobileNetV2(\n",
        "    \n",
        "        weights='imagenet',\n",
        "        input_shape = (224, 224, 3))\n",
        "\n",
        "\n",
        "time1_M = time.time()\n",
        "predictions = base_model.predict(data)\n",
        "time2_M=time.time()\n",
        "\n",
        "print(\"Inference average speed of MobileNetV2: \"+ str((time2_M-time1_M)/10))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14540800/14536120 [==============================] - 0s 0us/step\n",
            "14548992/14536120 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39e3db950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Inference average speed of MobileNetV2: 0.09537432193756104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smhpFW23qT9M",
        "outputId": "2cc622df-8cab-4cd8-82fd-e60d1cc13514"
      },
      "source": [
        "model = tf.keras.applications.resnet50.ResNet50(\n",
        "    \n",
        "    weights='imagenet', \n",
        "    input_shape=(224, 224, 3),\n",
        "    )\n",
        "time1_R = time.time()\n",
        "predictions = model.predict(data)\n",
        "time2_R = time.time()\n",
        "\n",
        "print(\"Inference average speed of ResNet50: \"+str((time2_R - time1_R)/10))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n",
            "Inference average speed of ResNet50: 0.22385408878326415\n"
          ]
        }
      ]
    }
  ]
}